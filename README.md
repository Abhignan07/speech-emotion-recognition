# ğŸ­ MultiModal Emotion Recognition
A deep learning project for **speech-based emotion recognition**. The system preprocesses audio data, trains a model, and provides predictions through an interactive **Streamlit web application**.

---

## ğŸš€ Features
- ğŸ™ï¸ Extracts MFCC features from audio signals  
- ğŸ§  Trains a neural network for emotion classification  
- ğŸ“Š Visualizes training performance  
- ğŸŒ Deployable via **Streamlit** web app  
- ğŸ“ Modular code structure for easy extension  

---

## ğŸ“‚ Folder Structure
```bash
MultiModal-Emotion-Recognition/
â”‚â”€â”€ app.py                # Streamlit web application
â”‚â”€â”€ requirements.txt      # Dependencies
â”‚â”€â”€ README.md             # Project documentation
â”‚
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ preprocess.py     # Data preprocessing & feature extraction
â”‚   â”œâ”€â”€ train_model.py    # Model training script
â”‚   â”œâ”€â”€ predict.py        # Inference script
â”‚
â””â”€â”€ saved_model/          # Saved models
    â”œâ”€â”€ emotion_model.h5  # Trained model
    â””â”€â”€ label_encoder.pkl # Label encoder
```

---

## ğŸ› ï¸ Installation
1. Clone the repository
```bash
git clone https://github.com/Abhignan07/speech-emotion-recognition.git
cd MultiModal-Emotion-Recognition
```
2. Create & activate virtual environment (optional but recommended)
```bash
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
```

3. Install dependencies
```bash
pip install -r requirements.txt
```
4. Download Dataset

This project uses the Toronto Emotional Speech Set (TESS).
ğŸ‘‰ [Download here](https://tspace.library.utoronto.ca/handle/1807/24487)

 Extract the dataset and place it in a folder named `data/` inside the project.

---

## ğŸ“Š Training the Model

To train the model on your dataset:
```bash
python src/train_model.py
```

Model will be saved in `saved_model/emotion_model.h5`

Encoder will be saved in `saved_model/label_encoder.pkl`

---

## ğŸ”® Running Predictions

You can test predictions on an audio file using:
```bash
python src/predict.py --file path_to_audio.wav
```
## ğŸŒ Running the Streamlit Web App

Launch the app:
```bash
streamlit run app.py
```

Then open the browser at the URL shown in the terminal (usually `http://localhost:8501`).

## ğŸ“Œ Notes

Dataset is ignored in Git (.gitignore) for size/privacy reasons.

Large model files (.h5, .pkl) may also be excluded from GitHub if they exceed limits.

Use tools like Git LFS for large file versioning if needed.

---

## Author

**Abhignan07**  
GitHub: [@Abhignan07](https://github.com/Abhignan07)  
Feel free to contribute or reach out with questions!

---
